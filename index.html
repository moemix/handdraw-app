<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>HandDraw — Object-Fit Cover Correct Overlay</title>
  <style>
    :root { --bg:#0b0e12; --fg:#e7eef7; --muted:#8391a3; }
    * { box-sizing: border-box; }
    html, body { height: 100%; margin: 0; background: var(--bg); color: var(--fg); font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; }
    .app {
      height: 100dvh; width: 100vw; display: grid; grid-template-rows: auto 1fr auto; gap: 8px; padding: 12px; }
    header, footer { opacity: .8; font-size: 14px; }
    .stage {
      position: relative; width: 100%; height: 100%; border-radius: 14px; overflow: hidden; background: #0f131a; box-shadow: 0 2px 24px rgba(0,0,0,.4) inset;
    }
    video#camera {
      position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); /* mirror selfie view */
      background: #111; opacity: 0.98;
    }
    canvas#overlay { position: absolute; inset: 0; pointer-events: none; }
    .hud { position: absolute; right: 10px; top: 10px; background: rgba(3,6,10,.5); backdrop-filter: blur(6px); border: 1px solid rgba(255,255,255,.06); padding: 8px 10px; border-radius: 10px; font-size: 12px; color: var(--muted); }
    .controls { display: flex; gap: 10px; align-items: center; flex-wrap: wrap; }
    label { display: inline-flex; gap: 6px; align-items: center; }
    input[type="checkbox"] { accent-color: #4aa3ff; }
    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
  </style>
</head>
<body>
  <div class="app">
    <header>
      <strong>HandDraw</strong> — precise overlay alignment (object-fit: <span class="mono">cover</span> safe)
    </header>
    <div class="stage" id="stage">
      <video id="camera" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
      <div class="hud">
        <div class="controls">
          <label title="Use pixel-snapped lines for razor-sharp rendering"><input type="checkbox" id="snapPx" checked> snap px</label>
          <label title="Flip overlay horizontally to match mirrored video"><input type="checkbox" id="mirror" checked> mirror overlay</label>
          <span id="info" class="mono">—</span>
        </div>
      </div>
    </div>
    <footer>
      Drop-in utility: call <span class="mono">window.drawLandmarks(landmarks)</span> where each landmark is <span class="mono">{x,y}</span> normalized to the source video.
    </footer>
  </div>

<script>
// ------ Display & Overlay Mapper (object-fit: cover compensation) ------
(function() {
  const video = document.getElementById('camera');
  const canvas = document.getElementById('overlay');
  const info = document.getElementById('info');
  const snapPx = document.getElementById('snapPx');
  const mirrorToggle = document.getElementById('mirror');
  const ctx = canvas.getContext('2d');

  // Keep measurements for mapping
  let layout = {
    containerW: 0, containerH: 0,
    videoW: 0, videoH: 0,
    scale: 1, drawnW: 0, drawnH: 0,
    offsetX: 0, offsetY: 0,
  };

  // Compute mapping from source video space -> displayed pixels (cover)
  function computeLayout() {
    const stage = document.getElementById('stage');
    const cw = stage.clientWidth;
    const ch = stage.clientHeight;
    const vw = video.videoWidth || 1280; // fallback until metadata
    const vh = video.videoHeight || 720;

    const scale = Math.max(cw / vw, ch / vh); // cover
    const drawnW = vw * scale;
    const drawnH = vh * scale;
    const offsetX = (cw - drawnW) / 2;
    const offsetY = (ch - drawnH) / 2;

    layout = { containerW: cw, containerH: ch, videoW: vw, videoH: vh, scale, drawnW, drawnH, offsetX, offsetY };

    // Resize canvas for sharp rendering at devicePixelRatio, but CSS-pixel match the stage
    const dpr = Math.max(1, window.devicePixelRatio || 1);
    canvas.style.width = cw + 'px';
    canvas.style.height = ch + 'px';
    canvas.width = Math.round(cw * dpr);
    canvas.height = Math.round(ch * dpr);
    ctx.setTransform(dpr, 0, 0, dpr, 0, 0); // logical units = CSS px
  }

  // Map a normalized point (0..1 in source video space) to displayed pixels
  function mapPoint(pt /* {x,y} in [0,1] */) {
    const x = pt.x * layout.videoW * layout.scale + layout.offsetX;
    const y = pt.y * layout.videoH * layout.scale + layout.offsetY;
    return { x, y };
  }

  // Map an array of normalized points
  function mapPoints(points) { return points.map(mapPoint); }

  // Optional crisp 1px lines using half-pixel translate
  function crisp() {
    if (!snapPx.checked) return;
    ctx.translate(0.5, 0.5);
  }

  // Public: draw landmarks (array of {x,y} normalized to source video)
  function drawLandmarks(landmarks, {connections, color='white', radius=3, lineWidth=2} = {}) {
    if (!landmarks || !landmarks.length) return;
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // Handle mirroring: video is mirrored via CSS transform, mirror overlay to match
    ctx.save();
    if (mirrorToggle.checked) {
      ctx.translate(layout.containerW, 0);
      ctx.scale(-1, 1);
    }

    crisp();

    const px = mapPoints(landmarks);

    // Draw connections first
    if (connections && connections.length) {
      ctx.beginPath();
      ctx.lineWidth = lineWidth; ctx.strokeStyle = color; ctx.globalAlpha = 0.9;
      for (const [a, b] of connections) {
        const p = px[a], q = px[b];
        ctx.moveTo(p.x, p.y); ctx.lineTo(q.x, q.y);
      }
      ctx.stroke();
    }

    // Draw points
    ctx.fillStyle = color; ctx.globalAlpha = 1;
    for (const p of px) {
      ctx.beginPath();
      ctx.arc(p.x, p.y, radius, 0, Math.PI * 2);
      ctx.fill();
    }

    ctx.restore();
  }

  // Expose for integration: pass normalized landmarks from your detector
  window.drawLandmarks = drawLandmarks;
  // Also expose mapper if you need exact pixel coords
  window.mapPointFromNormalized = mapPoint;

  // Keep info label updated for debugging
  function updateInfo() {
    const {containerW, containerH, videoW, videoH, scale, offsetX, offsetY} = layout;
    info.textContent = `src ${videoW}×${videoH} | view ${containerW}×${containerH} | scale ${scale.toFixed(3)} | offset (${offsetX.toFixed(1)},${offsetY.toFixed(1)})`;
  }

  // Resize observer keeps canvas aligned to the stage
  const ro = new ResizeObserver(() => { computeLayout(); updateInfo(); });
  ro.observe(document.getElementById('stage'));

  // Recompute when video metadata (intrinsic size) is ready
  video.addEventListener('loadedmetadata', () => { computeLayout(); updateInfo(); });

  // --- Camera bootstrap ---
  async function startCam() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
      video.srcObject = stream;
    } catch (err) {
      console.error('getUserMedia failed', err);
    }
  }
  startCam();

  // --- Demo mode (optional): press D to simulate a hand with normalized points ---
  // This helps validate that the mapping stays pixel-perfect across aspect ratios.
  let demoOn = true;
  document.addEventListener('keydown', (e) => { if (e.key.toLowerCase() === 'd') demoOn = !demoOn; });

  function demoFrame(t) {
    if (demoOn) {
      // Build a little animated spiral in normalized video space
      const n = 21; const pts = []; const cx = 0.5, cy = 0.5; const r = 0.25;
      for (let i = 0; i < n; i++) {
        const a = i / (n - 1) * Math.PI * 2 + t * 0.0015;
        const rr = r * (i / n);
        pts.push({ x: cx + Math.cos(a) * rr, y: cy + Math.sin(a) * rr });
      }
      drawLandmarks(pts, { connections: Array.from({length:n-1}, (_,i)=>[i,i+1]) });
    }
    requestAnimationFrame(demoFrame);
  }
  requestAnimationFrame(demoFrame);
})();
</script>
</body>
</html>
